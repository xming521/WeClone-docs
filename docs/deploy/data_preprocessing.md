# æ•°æ®é¢„å¤„ç†

åŸå§‹çš„èŠå¤©è®°å½•éœ€è¦ç»è¿‡é¢„å¤„ç†æ‰èƒ½ç”¨äºæ¨¡å‹è®­ç»ƒã€‚

* **é»˜è®¤å¤„ç†ï¼š** WeClone é¡¹ç›®é»˜è®¤ä¼šå»é™¤æ•°æ®ä¸­çš„æ‰‹æœºå·ã€èº«ä»½è¯å·ã€é‚®ç®±å’Œç½‘å€ã€‚
* **è‡ªå®šä¹‰è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰ï¼š** é¡¹ç›®æä¾›äº†ä¸€ä¸ªç¦ç”¨è¯è¯åº“ ï¼Œåœ¨æœ€æ–°çš„ä»£ç ä¸­è¿™ä¸ªè¯åº“è¢«ç§»åŠ¨åˆ°äº†`settings.jsonc`çš„`blocked_words`ã€‚ä½ å¯ä»¥å‘å…¶ä¸­æ·»åŠ ä¸å¸Œæœ›å‡ºç°åœ¨è®­ç»ƒæ•°æ®ä¸­çš„è¯å¥ï¼ˆåŒ…å«ç¦ç”¨è¯çš„æ•´å¥ä¼šè¢«è¿‡æ»¤æ‰ï¼‰ã€‚

## **æ‰§è¡Œé¢„å¤„ç†è„šæœ¬ï¼š**

åœ¨æ¿€æ´»è™šæ‹Ÿç¯å¢ƒçš„å‘½ä»¤è¡Œä¸­ï¼Œè¿›å…¥ WeClone é¡¹ç›®æ ¹ç›®å½•ï¼Œè¿è¡Œï¼š

```bash
weclone-cli make-dataset  #åœ¨WeCloneæ ¹ç›®å½•ä¸‹æ‰§è¡Œè¯¥å‘½ä»¤
```

* `WeClone` é»˜è®¤å¯ç”¨äº† `clean_dataset` é…ç½®ä¸­çš„ `enable_clean` é€‰é¡¹ï¼Œä¼šå¯¹åŸå§‹æ•°æ®è¿›è¡Œæ¸…æ´—ï¼Œä»¥æå‡åç»­å¤„ç†æ•ˆæœã€‚å½“å‰ç³»ç»Ÿæ”¯æŒä½¿ç”¨ `llm judge` å¯¹èŠå¤©è®°å½•è¿›è¡Œæ‰“åˆ†ï¼Œæä¾› **vllm ç¦»çº¿æ¨ç†** å’Œ **API åœ¨çº¿æ¨ç†** ä¸¤ç§æ–¹å¼ã€‚ä½ å¯ä»¥é€šè¿‡å°† `settings.jsonc` æ–‡ä»¶ä¸­çš„ `"online_llm_clear": false` ä¿®æ”¹ä¸º `true` æ¥å¯ç”¨ API åœ¨çº¿æ¨ç†æ¨¡å¼ï¼Œå¹¶é…ç½®ç›¸åº”çš„ `base_url`ã€`llm_api_key`ã€`model_name` ç­‰å‚æ•°ã€‚æ‰€æœ‰å…¼å®¹ OpenAI æ¥å£çš„æ¨¡å‹å‡å¯æ¥å…¥ï¼Œä½†éœ€æ³¨æ„ä½¿ç”¨ API å¯èƒ½å¸¦æ¥é¢å¤–æˆæœ¬ã€‚

* åœ¨è·å¾— `llm æ‰“åˆ†åˆ†æ•°åˆ†å¸ƒæƒ…å†µ` åï¼Œå¯é€šè¿‡è®¾ç½® `accept_score` å‚æ•°ç­›é€‰å¯æ¥å—çš„åˆ†æ•°åŒºé—´ï¼ŒåŒæ—¶å¯é€‚å½“é™ä½ `train_sft_args` ä¸­çš„ `lora_dropout` å‚æ•°ï¼Œä»¥æå‡æ¨¡å‹çš„æ‹Ÿåˆæ•ˆæœã€‚è¯·æ³¨æ„ï¼Œ**çº¯ Windows å¹³å°çš„ç”¨æˆ·æ— æ³•ä½¿ç”¨ vllm ç¦»çº¿æ¨ç†åŠŸèƒ½**ã€‚

* é¢„å¤„ç†å®Œæˆåï¼Œæ•°æ®é€šå¸¸ä¼šä¿å­˜åœ¨ `\WeClone\dataset\res_csv\sft` ç›®å½•æˆ–å…¶å­ç›®å½•ä¸‹çš„ `sft-my.json` æ–‡ä»¶ä¸­ã€‚

  

## ğŸ’¡ ä½¿ç”¨ vLLM æ—¶çš„æ³¨æ„äº‹é¡¹

å¦‚æœä½ é€‰æ‹©ä½¿ç”¨**vllmè¿›è¡Œç¦»çº¿æ¨ç†**ï¼Œä¸”æ˜¾å­˜æœ‰é™ï¼Œéœ€è¦å¯ç”¨**vLLMçš„`bitsandbytes`é‡åŒ–åŠ è½½**ï¼Œå¦åˆ™è¿™ä¸€æ­¥ä¹Ÿå¯èƒ½ä¼šçˆ†æ˜¾å­˜ã€‚è¿›ä¸€æ­¥è°ƒæ•´ã€ä¼˜åŒ–`vllm`å‚æ•°è¯·æŸ¥è¯¢[ vLLM å¼•æ“å‚æ•° ](https://docs.vllm.com.cn/en/latest/serving/engine_args.html#engine-args)

```python
# åœ¨ä¸‹é¢ä»£ç ä¸­çš„engine_argsæ–°å¢å‚æ•°
# weclone/core/inference/vllm_infer.py

engine_args = {
    "model": model_args.model_name_or_path,
    "trust_remote_code": True,
    "dtype": model_args.infer_dtype
    "max_model_len": cutoff_len + max_new_tokens,
    "enable_lora": model_args.adapter_name_or_path is not None,
    "enable_prefix_caching": True,

    # â†“ æ–°å¢å†…å®¹ â†“
    "quantization": "bitsandbytes",
    "load_format": "bitsandbytes",
}
```
>[!TIP]
> å¦‚æœé‡åˆ°æŠ¥é”™`ImportError: Please install bitsandbytes>=0.45.3`ï¼Œå¯ä»¥å°è¯•é‡æ–°å®‰è£…`bitsandbytes`ï¼š
> ```bash
> #ä½¿ç”¨uvå®‰è£… bitsandbytesï¼Œå»ºè®®ç§‘å­¦ä¸Šç½‘
> uv pip install bitsandbytes>=0.39.0
> ```

* æ­¤å¤–å¦‚æœä½ ä½¿ç”¨äº†å‹å·æ¯”è¾ƒè€çš„GPUï¼ˆä¾‹å¦‚ï¼Œè®¡ç®—èƒ½åŠ› Compute Capability ä½äº 8.0 çš„NVIDIA GPUï¼Œå¦‚Tesla T4, V100, GTX 10xx/20xxç³»åˆ—ç­‰ï¼‰å¯èƒ½ä¼šé‡åˆ°ä¸‹é¢æŠ¥é”™ï¼š

  ```bash
  ValueError: Bfloat16 is only supported on GPUs with compute capability of at least 8.0. Your xxx GPU has compute capability xx. You can use float16 instead by explicitly setting the idtype flag in CLI, for ecample: --dtype=half.
  ```

  è¿™æ˜¯å› ä¸ºï¼š `bfloat16` (BF16) æ˜¯ä¸€ç§è¾ƒæ–°çš„æµ®ç‚¹æ•°æ ¼å¼ï¼Œéœ€è¦GPUç¡¬ä»¶è¾¾åˆ°ä¸€å®šçš„è®¡ç®—èƒ½åŠ›ï¼ˆé€šå¸¸æ˜¯NVIDIA Ampereæ¶æ„åŠæ›´æ–°çš„GPUï¼Œè®¡ç®—èƒ½åŠ› >= 8.0ï¼‰æ‰èƒ½åŸç”Ÿæ”¯æŒã€‚å¦‚æœæ¨¡å‹é»˜è®¤å°è¯•ä»¥ `bfloat16` åŠ è½½ï¼Œè€Œä½ çš„GPUä¸æ”¯æŒï¼Œå°±ä¼šå‡ºç°è¿™ä¸ªé”™è¯¯ã€‚è¿™æ—¶å€™ä½ å¯ä»¥å°è¯•åœ¨åŸæœ¬çš„`CLI`ååŠ ä¸Š`--dtype=half`ç„¶åé‡æ–°æ‰§è¡Œï¼š

  ```bash
  weclone-cli make-dataset --dtype=half
  ```

  æˆ–è€…åœ¨`settings.jsonc`ä¸­å¢åŠ ä»¥ä¸‹å‚æ•°ï¼Œç„¶åé‡æ–°æ‰§è¡Œ`weclone-cli make-dataset`ï¼Œçœ‹é—®é¢˜æ˜¯å¦è§£å†³ã€‚

  ```json
  "infer_args": {
      "repetition_penalty": 1.2,
      "temperature": 0.5,
      "max_length": 50,
      "top_p": 0.65,
      "infer_dtype": "float16"  // æ·»åŠ è¿™ä¸€è¡Œ
  }
  ```