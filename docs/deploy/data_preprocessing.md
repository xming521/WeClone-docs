# æ•°æ®é¢„å¤„ç†

åŸå§‹çš„èŠå¤©è®°å½•éœ€è¦ç»è¿‡é¢„å¤„ç†æ‰èƒ½ç”¨äºæ¨¡å‹è®­ç»ƒ
é¢„å¤„ç†è¿‡ç¨‹ä¼šä½¿ç”¨Microsoft Presidioè¿›è¡ŒPIIï¼ˆä¸ªäººèº«ä»½ä¿¡æ¯ï¼‰æ•°æ®çš„è¿‡æ»¤ã€‚

* **é»˜è®¤è¿‡æ»¤ï¼š** é»˜è®¤ä¼šå»é™¤æ•°æ®ä¸­çš„`ç”µè¯å·ç ã€ç”µå­é‚®ä»¶åœ°å€ã€ä¿¡ç”¨å¡å·ç ã€IPåœ°å€ã€åœ°ç†ä½ç½®åç§°ã€å›½é™…é“¶è¡Œè´¦æˆ·å·ç ã€åŠ å¯†è´§å¸é’±åŒ…åœ°å€ã€å¹´é¾„ä¿¡æ¯ã€é€šç”¨èº«ä»½è¯å·ç `ç­‰PII,ä½†æ˜¯ä¸èƒ½ä¿è¯100%è¯†åˆ«ã€‚
* **è‡ªå®šä¹‰è¿‡æ»¤ï¼š** é¡¹ç›®æä¾›äº†ä¸€ä¸ªç¦ç”¨è¯è¯åº“å‚æ•°`blocked_words`ã€‚ä½ å¯ä»¥å‘å…¶ä¸­æ·»åŠ ä¸å¸Œæœ›å‡ºç°åœ¨è®­ç»ƒæ•°æ®ä¸­çš„è¯å¥ï¼ˆåŒ…å«ç¦ç”¨è¯çš„æ•´å¥ä¼šè¢«è¿‡æ»¤æ‰ï¼‰ã€‚

## **æ‰§è¡Œé¢„å¤„ç†è„šæœ¬ï¼š**

åœ¨æ¿€æ´»è™šæ‹Ÿç¯å¢ƒçš„å‘½ä»¤è¡Œä¸­ï¼Œè¿›å…¥ WeClone é¡¹ç›®æ ¹ç›®å½•ï¼Œè¿è¡Œï¼š
```bash
weclone-cli make-dataset  
```

- ç›®å‰æ”¯æŒæ—¶é—´çª—å£ç­–ç•¥ï¼Œæ ¹æ®`single_combine_time_window`å°†å•äººè¿ç»­æ¶ˆæ¯é€šè¿‡é€—å·è¿æ¥åˆå¹¶ä¸ºä¸€å¥ï¼Œæ ¹æ®`qa_match_time_window`åŒ¹é…é—®ç­”å¯¹ã€‚
- **è®­ç»ƒå¤šæ¨¡æ€å¤§æ¨¡å‹**:åœ¨`include_type`ä¸­æ·»åŠ `images`å¯ç”¨ï¼Œå¹¶é€šè¿‡`image_max_pixels`å’Œ`max_image_num`å‚æ•°æ§åˆ¶å›¾ç‰‡æ•°é‡å’Œå¤§å°ï¼Œä»¥å‡å°‘æ˜¾å­˜å ç”¨ã€‚
- **Image to Text**:åœ¨`include_type`ä¸­æ·»åŠ `images`å¹¶é…ç½® `vision_api` å‚æ•°ï¼Œå°†ä½¿ç”¨å¤–éƒ¨å¤šæ¨¡æ€æ¨¡å‹å°†å›¾ç‰‡è½¬ä¸ºæ–‡æœ¬ï¼Œæœ€ç»ˆç”Ÿæˆçš„æ•°æ®é›†**ä»ç”¨äºè®­ç»ƒçº¯æ–‡æœ¬è¯­è¨€æ¨¡å‹**ã€‚
- å¯ä»¥å¯ç”¨`clean_dataset`ä¸­çš„`enable_clean`é€‰é¡¹ï¼Œå¯¹æ•°æ®è¿›è¡Œæ¸…æ´—ï¼Œä»¥è¾¾åˆ°æ›´å¥½æ•ˆæœï¼ˆå¤šæ¨¡æ€æ•°æ®æš‚ä¸æ”¯æŒï¼‰ã€‚* å½“å‰æ”¯æŒä½¿ç”¨ `llm judge` å¯¹èŠå¤©è®°å½•è¿›è¡Œæ‰“åˆ†ï¼Œæä¾› **vllm ç¦»çº¿æ¨ç†** å’Œ **API åœ¨çº¿æ¨ç†** ä¸¤ç§æ–¹å¼ã€‚é»˜è®¤ç¦»çº¿æ¨ç†ï¼Œå¯é€šè¿‡å°† `settings.jsonc` æ–‡ä»¶ä¸­çš„ `"online_llm_clear": false` ä¿®æ”¹ä¸º `true` æ¥å¯ç”¨ API åœ¨çº¿æ¨ç†æ¨¡å¼ï¼Œå¹¶é…ç½®ç›¸åº”çš„ `base_url`ã€`llm_api_key`ã€`model_name` ç­‰å‚æ•°ã€‚æ‰€æœ‰å…¼å®¹ OpenAI æ¥å£çš„æ¨¡å‹å‡å¯æ¥å…¥ã€‚
- åœ¨è·å¾— `llm æ‰“åˆ†åˆ†æ•°åˆ†å¸ƒ` åï¼Œå¯é€šè¿‡è®¾ç½® `accept_score` å‚æ•°ç­›é€‰å¯æ¥å—çš„æ•°æ®ï¼ŒåŒæ—¶å¯é€‚å½“é™ä½ `train_sft_args` ä¸­çš„ `lora_dropout` å‚æ•°ï¼Œä»¥æå‡æ¨¡å‹çš„æ‹Ÿåˆæ•ˆæœã€‚

* é¢„å¤„ç†å®Œæˆåï¼Œæ•°æ®é€šå¸¸ä¼šä¿å­˜åœ¨ `.\dataset\res_csv\sft` ç›®å½•æˆ–å…¶å­ç›®å½•ä¸‹çš„ `sft-my.json` æ–‡ä»¶ä¸­ã€‚

  

## ğŸ’¡ ä½¿ç”¨ vLLM æ—¶çš„æ³¨æ„äº‹é¡¹

å¦‚æœä½ é€‰æ‹©ä½¿ç”¨**vllmè¿›è¡Œç¦»çº¿æ¨ç†**ï¼Œä¸”æ˜¾å­˜æœ‰é™ï¼Œéœ€è¦å¯ç”¨**vLLMçš„`bitsandbytes`é‡åŒ–åŠ è½½**ï¼Œå¦åˆ™è¿™ä¸€æ­¥ä¹Ÿå¯èƒ½ä¼šçˆ†æ˜¾å­˜ã€‚è¿›ä¸€æ­¥è°ƒæ•´ã€ä¼˜åŒ–`vllm`å‚æ•°è¯·æŸ¥è¯¢[ vLLM å¼•æ“å‚æ•° ](https://docs.vllm.com.cn/en/latest/serving/engine_args.html#engine-args)

```python
# åœ¨ä¸‹é¢ä»£ç ä¸­çš„engine_argsæ–°å¢å‚æ•°
# weclone/core/inference/vllm_infer.py

engine_args = {
    "model": model_args.model_name_or_path,
    "trust_remote_code": True,
    "dtype": model_args.infer_dtype
    "max_model_len": cutoff_len + max_new_tokens,
    "enable_lora": model_args.adapter_name_or_path is not None,
    "enable_prefix_caching": True,

    # â†“ æ–°å¢å†…å®¹ â†“
    "quantization": "bitsandbytes",
    "load_format": "bitsandbytes",
}
```
>[!TIP]
> å¦‚æœé‡åˆ°æŠ¥é”™`ImportError: Please install bitsandbytes>=0.45.3`ï¼Œå¯ä»¥å°è¯•é‡æ–°å®‰è£…`bitsandbytes`ï¼š
> ```bash
> #ä½¿ç”¨uvå®‰è£… bitsandbytesï¼Œå»ºè®®ç§‘å­¦ä¸Šç½‘
> uv pip install bitsandbytes>=0.39.0
> ```

* æ­¤å¤–å¦‚æœä½ ä½¿ç”¨äº†å‹å·æ¯”è¾ƒè€çš„GPUï¼ˆä¾‹å¦‚ï¼Œè®¡ç®—èƒ½åŠ› Compute Capability ä½äº 8.0 çš„NVIDIA GPUï¼Œå¦‚Tesla T4, V100, GTX 10xx/20xxç³»åˆ—ç­‰ï¼‰å¯èƒ½ä¼šé‡åˆ°ä¸‹é¢æŠ¥é”™ï¼š

  ```bash
  ValueError: Bfloat16 is only supported on GPUs with compute capability of at least 8.0. Your xxx GPU has compute capability xx. You can use float16 instead by explicitly setting the idtype flag in CLI, for ecample: --dtype=half.
  ```

  è¿™æ˜¯å› ä¸ºï¼š `bfloat16` (BF16) æ˜¯ä¸€ç§è¾ƒæ–°çš„æµ®ç‚¹æ•°æ ¼å¼ï¼Œéœ€è¦GPUç¡¬ä»¶è¾¾åˆ°ä¸€å®šçš„è®¡ç®—èƒ½åŠ›ï¼ˆé€šå¸¸æ˜¯NVIDIA Ampereæ¶æ„åŠæ›´æ–°çš„GPUï¼Œè®¡ç®—èƒ½åŠ› >= 8.0ï¼‰æ‰èƒ½åŸç”Ÿæ”¯æŒã€‚å¦‚æœæ¨¡å‹é»˜è®¤å°è¯•ä»¥ `bfloat16` åŠ è½½ï¼Œè€Œä½ çš„GPUä¸æ”¯æŒï¼Œå°±ä¼šå‡ºç°è¿™ä¸ªé”™è¯¯ã€‚è¿™æ—¶å€™ä½ å¯ä»¥å°è¯•åœ¨åŸæœ¬çš„`CLI`ååŠ ä¸Š`--dtype=half`ç„¶åé‡æ–°æ‰§è¡Œï¼š

  ```bash
  weclone-cli make-dataset --dtype=half
  ```

  æˆ–è€…åœ¨`settings.jsonc`ä¸­å¢åŠ ä»¥ä¸‹å‚æ•°ï¼Œç„¶åé‡æ–°æ‰§è¡Œ`weclone-cli make-dataset`ï¼Œçœ‹é—®é¢˜æ˜¯å¦è§£å†³ã€‚

  ```json
  "infer_args": {
      "repetition_penalty": 1.2,
      "temperature": 0.5,
      "max_length": 50,
      "top_p": 0.65,
      "infer_dtype": "float16"  // æ·»åŠ è¿™ä¸€è¡Œ
  }
  ```